{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5bd9fa7-f703-491f-bb42-a82c42a640bf",
   "metadata": {},
   "source": [
    "# Processing DODS Stored NLDAS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd644855-bf73-43ea-9a75-04d23aec7190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6e03c1-58e7-485f-894f-c43906e9605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#\n",
    "# Library \n",
    "#\n",
    "\n",
    "import numpy             as np\n",
    "import xarray            as xr\n",
    "import matplotlib        as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime          as datetime\n",
    "import pandas            as pd\n",
    "import earthaccess       as earthaccess\n",
    "import os                as os\n",
    "import h5netcdf          as h5netcdf\n",
    "import platform          as platform\n",
    "\n",
    "import cartopy.crs       as ccrs\n",
    "import cartopy.feature   as cfeature\n",
    "\n",
    "#\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8785f2c3-6704-4576-a4f0-56c0b4f5bb08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b6590c-2866-4262-8c1a-79c2fd9fb1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#\n",
    "# Getting Spatial Metadata \n",
    "#\n",
    "\n",
    "xf_metadata = xr.open_dataset(filename_or_obj = \"./NLDAS_METADATA.nc\")\n",
    "xf_metadata\n",
    "\n",
    "nx   = xf_metadata[\"lon\"].values.size\n",
    "ny   = xf_metadata[\"lat\"].values.size\n",
    "nt_h = 24\n",
    "\n",
    "#\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf5983a-a4ac-4147-99a7-4eaa73a3ab94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "#\n",
    "# Getting Variable Lookup Tables \n",
    "#\n",
    "\n",
    "df_varlut = pd.read_csv(filepath_or_buffer = \"./metadata_lookup.csv\", index_col=\"INDEX\")\n",
    "\n",
    "#\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893719d9-3329-4a76-8497-37390af0155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#\n",
    "# Data Sets and EarthAccess \n",
    "#\n",
    "\n",
    "if (platform.system() == \"Linux\"):\n",
    "    root_dir = \"/data/DATASETS/NLDAS/netcdf/\"\n",
    "else:\n",
    "    root_dir = \"./data/\"\n",
    "\n",
    "\n",
    "doi_nldas_noah  = \"10.5067/T4OW83T8EXDO\"\n",
    "doi_nldas_force = \"10.5067/THUF4J1RLSYG\"\n",
    "\n",
    "auth            = earthaccess.login()\n",
    "\n",
    "dt              = 3600.\n",
    "\n",
    "#\n",
    "#################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060b7f42-50f1-476f-8191-be1d10832847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#\n",
    "# Date Range\n",
    "#\n",
    "\n",
    "start_date = np.datetime64('1979-01-02')\n",
    "end_date   = np.datetime64('1979-01-04')\n",
    "date_range = np.arange(start_date, end_date + np.timedelta64(1, 'D'))\n",
    "\n",
    "for working_date in date_range:\n",
    "    print(working_date)\n",
    "\n",
    "\n",
    "#\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4a5fc6-c7e2-4d64-9282-02d7de1ca9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#\n",
    "# Compression Encoding\n",
    "#\n",
    "\n",
    "variable_list = [\"mean_air_temperature\", \n",
    "                 \"specific_humidity\", \n",
    "                 \"air_pressure\", \n",
    "                 \"eastward_wind\", \n",
    "                 \"northward_wind\", \n",
    "                 \"atmosphere_convective_available_potential_energy\", \n",
    "                 \"surface_downward_shortwave_flux\", \n",
    "                 \"surface_downward_longwave_flux\", \n",
    "                 \"surface_net_downward_shortwave_flux\", \n",
    "                 \"surface_net_downward_longwave_flux\", \n",
    "                 \"surface_upward_latent_heat_flux\", \n",
    "                 \"surface_sensible_heat_flux\", \n",
    "                 \"downward_heat_flux_at_ground_level_in_soil\", \n",
    "                 \"surface_snow_and_ice_refreezing_flux\", \n",
    "                 \"snowfall_amount\", \n",
    "                 \"precipitation_amount\", \n",
    "                 \"water_evapotranspiration_amount\", \n",
    "                 \"surface_runoff_amount\", \n",
    "                 \"subsurface_runoff_amount\", \n",
    "                 \"surface_snow_melt_amount\", \n",
    "                 \"surface_temperature\", \n",
    "                 \"surface_albedo\", \n",
    "                 \"liquid_water_content_of_surface_snow\", \n",
    "                 \"surface_snow_thickness\", \n",
    "                 \"surface_snow_area_fraction\", \n",
    "                 \"mass_content_of_water_in_soil_layer_defined_by_root_depth\", \n",
    "                 \"surface_upward_potential_latent_heat_flux\", \n",
    "                 \"upward_latent_heat_flux_into_air_due_to_evaporation_of_intercepted_precipitation\", \n",
    "                 \"upward_latent_heat_flux_into_air_due_to_transpiration\", \n",
    "                 \"upward_latent_heat_flux_into_air_due_to_evaporation_from_soil\", \n",
    "                 \"surface_snow_sublimation_heat_flux\", \n",
    "                 \"canopy_water_amount\", \n",
    "                 \"leaf_area_index\", \n",
    "                 \"vegetation_area_fraction\", \n",
    "                 \"water_volume_transport_in_river_channel\", \n",
    "                 \"liquid_water_content_of_soil_layer\",\n",
    "                 \"mass_content_of_water_in_soil_layer\",\n",
    "                 \"soil_temperature\",\n",
    "                 \"maximum_air_temperature\", \n",
    "                 \"minimum_air_temperature\"]\n",
    "\n",
    "\n",
    "encoding = {\"time\" :{\"units\":\"seconds since 1970-01-01 00:00:00\",\n",
    "                     \"dtype\":np.float64}}\n",
    "\n",
    "for variable in variable_list:\n",
    "    encoding[variable] = dict(zlib      =       True,\n",
    "                              complevel =          7, \n",
    "                              dtype     = np.float32)\n",
    "\n",
    "#\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ee76d-8f32-4126-8bb7-e9411684bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for working_date in date_range:\n",
    "\n",
    "    print(\"============================\")\n",
    "    \n",
    "    \n",
    "    #################################################\n",
    "    #\n",
    "    # Extract One Day of Data \n",
    "    #\n",
    "    \n",
    "    daily_date       = pd.to_datetime(working_date)\n",
    "    output_directory = root_dir + daily_date.strftime('%Y/%m/')\n",
    "    filedate         = daily_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    fileout          = \"NLDAS_NOAH_DAILY_\"+filedate+\".nc\"\n",
    "    print(\"Processing \"+filedate)\n",
    "    # This will work if Earthdata prerequisite files have already been generated\n",
    "    \n",
    "    results_noah  = earthaccess.search_data(doi      = doi_nldas_noah,\n",
    "                                            temporal = (filedate + ' 00:00:00', \n",
    "                                                        filedate + ' 23:59:00')) \n",
    "    \n",
    "    results_force = earthaccess.search_data(doi      = doi_nldas_force,\n",
    "                                            temporal = (filedate + ' 00:00:00', \n",
    "                                                        filedate + ' 23:59:00')) \n",
    "    \n",
    "    print(\"Opening EA-Noah\")\n",
    "    fs_noah  = earthaccess.open(results_noah)  # Extracts URLs from the results variable\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"---------------------------\")\n",
    "    print(\"Opening EA-Forcings\")\n",
    "    fs_force = earthaccess.open(results_force) # Extracts URLs from the results variable\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"---------------------------\")\n",
    "    print(\"Opening XR-Noah\")\n",
    "    ds_noah  = xr.open_mfdataset(paths = fs_noah)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"---------------------------\")\n",
    "    print(\"Opening XR-Forcings\")\n",
    "    ds_force = xr.open_mfdataset(paths = fs_force)\n",
    "    \n",
    "    #\n",
    "    #################################################\n",
    "    \n",
    "    #################################################\n",
    "    #\n",
    "    # Clean and Merge the NOAH and Forcing datasets\n",
    "    #\n",
    "    \n",
    "    ds_noah  =  ds_noah.drop_vars([\"SMAvail_0_100cm\",\n",
    "                                   \"SMAvail_0_200cm\",\n",
    "                                   \"SoilM_0_100cm\",\n",
    "                                   \"SoilM_0_200cm\",\n",
    "                                   \"ACond\",\n",
    "                                   \"CCond\",\n",
    "                                   \"RCS\",\n",
    "                                   \"RCT\",\n",
    "                                   \"RCQ\",\n",
    "                                   \"RCSOL\",\n",
    "                                   \"RSmin\",\n",
    "                                   \"RSMacr\"])\n",
    "    \n",
    "    ds_force = ds_force.drop_vars([\"SWdown\",\n",
    "                                   \"LWdown\",\n",
    "                                   \"PotEvap\",\n",
    "                                   \"Rainf\",\n",
    "                                   \"CRainf_frac\"])\n",
    "    \n",
    "    xf_noah_hourly = xr.merge([ds_force, \n",
    "                               ds_noah])\n",
    "    \n",
    "    del ds_noah\n",
    "    del ds_force\n",
    "    \n",
    "    \n",
    "    #\n",
    "    #################################################\n",
    "    \n",
    "    #################################################\n",
    "    #\n",
    "    # Reshape the Soils Parameters\n",
    "    #\n",
    "    \n",
    "    \n",
    "    xf_noah_hourly[\"soil_depth\"]      = xf_metadata[\"soil_depth\"]\n",
    "    xf_noah_hourly[\"soil_thickness\"]  = xf_metadata[\"soil_thickness\"]\n",
    "    xf_noah_hourly[\"soil_depth_bnds\"] = xf_metadata[\"soil_depth_bnds\"]\n",
    "    \n",
    "    soil_temp = xr.DataArray(data   = np.zeros(shape = [nt_h, 4, ny, nx], \n",
    "                                               dtype = np.float32),\n",
    "                             dims   = [\"time\",\"soil_depth\",\"lat\",\"lon\"],\n",
    "                             coords = {\"time\":xf_noah_hourly[\"time\"],\n",
    "                                       \"soil_depth\":xf_metadata[\"soil_depth\"],\n",
    "                                       \"lat\":xf_metadata[\"lat\"],\n",
    "                                       \"lon\":xf_metadata[\"lon\"]},\n",
    "                             attrs  = {\"description\":\"Soil Temperature\",\n",
    "                                       \"long_name\":\"Soil Temperature\",\n",
    "                                       \"standard_name\":\"soil_temperature\",\n",
    "                                       \"units\":\"K\"})\n",
    "    \n",
    "    soil_moist = xr.DataArray(data   = np.zeros(shape = [nt_h, 4, ny, nx], \n",
    "                                               dtype = np.float32),\n",
    "                             dims   = [\"time\",\"soil_depth\",\"lat\",\"lon\"],\n",
    "                             coords = {\"time\":xf_noah_hourly[\"time\"],\n",
    "                                       \"soil_depth\":xf_metadata[\"soil_depth\"],\n",
    "                                       \"lat\":xf_metadata[\"lat\"],\n",
    "                                       \"lon\":xf_metadata[\"lon\"]},\n",
    "                             attrs  = {\"description\":\"Soil Liquid Water Content\",\n",
    "                                       \"long_name\":\"Soil Liquid Water Content\",\n",
    "                                       \"standard_name\":\"mass_content_of_water_in_soil_layer\",\n",
    "                                       \"units\":\"kg m-2\"})\n",
    "    \n",
    "    soil_liq  = xr.DataArray(data   = np.zeros(shape = [nt_h, 4, ny, nx], \n",
    "                                               dtype = np.float32),\n",
    "                             dims   = [\"time\",\"soil_depth\",\"lat\",\"lon\"],\n",
    "                             coords = {\"time\":xf_noah_hourly[\"time\"],\n",
    "                                       \"soil_depth\":xf_metadata[\"soil_depth\"],\n",
    "                                       \"lat\":xf_metadata[\"lat\"],\n",
    "                                       \"lon\":xf_metadata[\"lon\"]},\n",
    "                             attrs  = {\"description\":\"Soil Liquid Water Content\",\n",
    "                                       \"long_name\":\"Soil Liquid Water Content\",\n",
    "                                       \"standard_name\":\"liquid_water_content_of_soil_layer\",\n",
    "                                       \"units\":\"kg m-2\"})\n",
    "    \n",
    "    xf_noah_hourly[\"liquid_water_content_of_soil_layer\"]  = soil_liq\n",
    "    xf_noah_hourly[\"mass_content_of_water_in_soil_layer\"] = soil_moist\n",
    "    xf_noah_hourly[\"soil_temperature\"]                    = soil_temp\n",
    "    \n",
    "    soil_liq.values[:,0,:,:] = xf_noah_hourly[\"SMLiq_0_10cm\"].values\n",
    "    soil_liq.values[:,1,:,:] = xf_noah_hourly[\"SMLiq_10_40cm\"].values\n",
    "    soil_liq.values[:,2,:,:] = xf_noah_hourly[\"SMLiq_40_100cm\"].values\n",
    "    soil_liq.values[:,3,:,:] = xf_noah_hourly[\"SMLiq_100_200cm\"].values \n",
    "    \n",
    "    soil_moist.values[:,0,:,:] = xf_noah_hourly[\"SoilM_0_10cm\"].values\n",
    "    soil_moist.values[:,1,:,:] = xf_noah_hourly[\"SoilM_10_40cm\"].values\n",
    "    soil_moist.values[:,2,:,:] = xf_noah_hourly[\"SoilM_40_100cm\"].values\n",
    "    soil_moist.values[:,3,:,:] = xf_noah_hourly[\"SoilM_100_200cm\"].values \n",
    "    \n",
    "    soil_temp.values[:,0,:,:] = xf_noah_hourly[\"SoilT_0_10cm\"].values\n",
    "    soil_temp.values[:,1,:,:] = xf_noah_hourly[\"SoilT_10_40cm\"].values\n",
    "    soil_temp.values[:,2,:,:] = xf_noah_hourly[\"SoilT_40_100cm\"].values\n",
    "    soil_temp.values[:,3,:,:] = xf_noah_hourly[\"SoilT_100_200cm\"].values \n",
    "    \n",
    "    del xf_noah_hourly[\"SoilT_0_10cm\"]\n",
    "    del xf_noah_hourly[\"SoilT_10_40cm\"]\n",
    "    del xf_noah_hourly[\"SoilT_40_100cm\"]\n",
    "    del xf_noah_hourly[\"SoilT_100_200cm\"]\n",
    "    \n",
    "    del xf_noah_hourly[\"SoilM_0_10cm\"]\n",
    "    del xf_noah_hourly[\"SoilM_10_40cm\"]\n",
    "    del xf_noah_hourly[\"SoilM_40_100cm\"]\n",
    "    del xf_noah_hourly[\"SoilM_100_200cm\"]\n",
    "    \n",
    "    del xf_noah_hourly[\"SMLiq_0_10cm\"]\n",
    "    del xf_noah_hourly[\"SMLiq_10_40cm\"]\n",
    "    del xf_noah_hourly[\"SMLiq_40_100cm\"]\n",
    "    del xf_noah_hourly[\"SMLiq_100_200cm\"]\n",
    "    \n",
    "    #\n",
    "    #################################################\n",
    "    \n",
    "    #################################################\n",
    "    #\n",
    "    # Change Variable Metadata for Hourly Data\n",
    "    #\n",
    "    \n",
    "    for index, row in df_varlut.iterrows():\n",
    "        xf_noah_hourly  = xf_noah_hourly.rename_vars(name_dict = {index:row[\"new_name\"]})\n",
    "        xf_noah_hourly[row[\"new_name\"]].attrs[\"long_name\"]     = row[\"long_name\"]\n",
    "        xf_noah_hourly[row[\"new_name\"]].attrs[\"description\"]   = row[\"long_name\"]\n",
    "        xf_noah_hourly[row[\"new_name\"]].attrs[\"standard_name\"] = row[\"standard_name\"]\n",
    "        xf_noah_hourly[row[\"new_name\"]].attrs[\"units\"]         = row[\"units_in\"]\n",
    "    \n",
    "        if (\"vmax\" in xf_noah_hourly[row[\"new_name\"]].attrs):\n",
    "            del xf_noah_hourly[row[\"new_name\"]].attrs[\"vmax\"]\n",
    "        if (\"vmin\" in xf_noah_hourly[row[\"new_name\"]].attrs):\n",
    "            del xf_noah_hourly[row[\"new_name\"]].attrs[\"vmin\"]\n",
    "    print(\"--------\")\n",
    "    \n",
    "    #\n",
    "    #################################################\n",
    "    \n",
    "    #################################################\n",
    "    #\n",
    "    # Aggregate Hourly to Daily Data\n",
    "    #\n",
    "    \n",
    "    print(\"Aggregating Daily Data\")\n",
    "    \n",
    "    xf_noah_daily = xf_noah_hourly.drop_vars(\"time_bounds\").coarsen(time=24).sum(skipna=False)\n",
    "    for index, row in df_varlut.drop(axis=\"columns\", index=[\"time\",\"time_bnds\"]).iterrows():\n",
    "        xf_noah_daily[row[\"new_name\"]].attrs[\"long_name\"]     = row[\"long_name\"]\n",
    "        xf_noah_daily[row[\"new_name\"]].attrs[\"description\"]   = row[\"long_name\"]\n",
    "        xf_noah_daily[row[\"new_name\"]].attrs[\"standard_name\"] = row[\"standard_name\"]\n",
    "        xf_noah_daily[row[\"new_name\"]].attrs[\"units\"]         = row[\"units_in\"]\n",
    "    \n",
    "    df_varlut_mean = df_varlut[ df_varlut[\"Aggregation\"] ==     \"MEAN\" ][\"new_name\"].to_list()\n",
    "    df_varlut_sum  = df_varlut[ df_varlut[\"Aggregation\"] ==      \"SUM\" ][\"new_name\"].to_list()\n",
    "    df_varlut_int  = df_varlut[ df_varlut[\"Aggregation\"] == \"INTEGRAL\" ][\"new_name\"].to_list()\n",
    "    \n",
    "    for variable in df_varlut_int:\n",
    "        xf_noah_daily[variable].values  = xf_noah_daily[variable].values * dt\n",
    "    \n",
    "    for variable in df_varlut_mean:\n",
    "        xf_noah_daily[variable].values  = xf_noah_daily[variable].values / 24.\n",
    "    \n",
    "    xf_noah_daily[\"maximum_air_temperature\"] = xf_noah_hourly[\"mean_air_temperature\"].coarsen(time=24).max(skipna=False)\n",
    "    xf_noah_daily[\"maximum_air_temperature\"].attrs[\"long_name\"]     = \"2-meter maximum air temperature\"\n",
    "    xf_noah_daily[\"maximum_air_temperature\"].attrs[\"description\"]   = \"2-meter maximum air temperature\"\n",
    "    xf_noah_daily[\"maximum_air_temperature\"].attrs[\"standard_name\"] = \"air_temperature\"\n",
    "    xf_noah_daily[\"maximum_air_temperature\"].attrs[\"units\"]         = \"K\"\n",
    "    \n",
    "    xf_noah_daily[\"minimum_air_temperature\"] = xf_noah_hourly[\"mean_air_temperature\"].coarsen(time=24).min(skipna=False)\n",
    "    xf_noah_daily[\"minimum_air_temperature\"].attrs[\"long_name\"]     = \"2-meter minimum air temperature\"\n",
    "    xf_noah_daily[\"minimum_air_temperature\"].attrs[\"description\"]   = \"2-meter minimum air temperature\"\n",
    "    xf_noah_daily[\"minimum_air_temperature\"].attrs[\"standard_name\"] = \"air_temperature\"\n",
    "    xf_noah_daily[\"minimum_air_temperature\"].attrs[\"units\"]         = \"K\"\n",
    "    \n",
    "    \n",
    "    #\n",
    "    #########################################################\n",
    "    \n",
    "    \n",
    "    #########################################################\n",
    "    #\n",
    "    # Write to File\n",
    "    #\n",
    "    \n",
    "    \n",
    "    del xf_noah_daily[\"time\"].attrs[\"units\"]\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(output_directory)\n",
    "    except FileExistsError:\n",
    "        print(output_directory + \" Exists\")\n",
    "    print(\"writing \"+output_directory + fileout)\n",
    "    xf_noah_daily.to_netcdf(path           = output_directory + fileout,\n",
    "                            unlimited_dims = \"time\",\n",
    "                            engine         = \"h5netcdf\",\n",
    "                            encoding       = encoding)\n",
    "    \n",
    "    #\n",
    "    #########################################################\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5f9e98-832f-4f8d-9961-b55c14bda3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddbeb71-32b3-4236-af72-1e5739cae6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9532f2bd-32c5-4090-bdf9-da7269d4bf4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea242e5b-49be-4b24-8a82-d1c5f4677062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c95dbc-40b1-4893-bbdd-be11f2312cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
